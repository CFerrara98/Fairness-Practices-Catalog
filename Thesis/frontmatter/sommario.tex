%\selectlanguage{italian}

\begin{center}
    \LARGE \textsc{Abstract}
\end{center}


Con il passare degli anni, nella società, si è sempre cercato di sensibilizzare le persone per un mondo più equo e senza discriminazioni. Oggigiorno un ruolo fondamentale lo hanno i social, i quali promuovono campagne di sensibilizzazione rivolte principalmente ai più giovani. La progressione tecnologica, quindi, ha sicuramente dato il proprio contributo per diffondere buone lezioni ai giovani, ma è da qualche anno che la tecnologia stessa ha evidenziato qualche problema con l'equità che tanto si difende. È successo ad Amazon tramite un sistema di scelta del personale intelligente, è successo a YouTube tramite il sistema intelligente di generazione dei sottotitoli, è successo ai software della polizia e delle strutture ospedaliere statunitensi: diverse persone sono state discriminate da software intelligenti perchè, magari, erano neri e donne. Ciò è inammissibile, l'argomento merita di essere approfondito: pertanto, tale tesi cerca di esplorare le motivazioni dietro tali accaduti comprendendo quali potrebbero essere le cause legate alle discriminazioni e quali potrebbero essere le buone pratiche da seguire per mitigarle quanto possibile. In breve, verrà proposta la compilazione di un questionario ad esperti del dominio provenienti da tutto il mondo, i quali forniranno le loro conoscenze circa come viene approcciata la fairness a lavoro e durante lo sviluppo dei software intelligenti, concentrandosi maggiormente sul trattamento di quest'ultima. L'obiettivo, quindi, è quello di arrivare a scoprire delle pratiche che potrebbero ridurre le probabilità di svolgere discriminazioni durante le predizioni.

